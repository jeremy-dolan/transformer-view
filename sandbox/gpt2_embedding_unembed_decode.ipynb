{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy~=1.0 in ./.venv/lib/python3.12/site-packages (1.26.4)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install numpy~=1.0\n",
    "%pip install torch -q\n",
    "%pip install transformers -q\n",
    "%pip install matplotlib -q\n",
    "\n",
    "import math\n",
    "import torch\n",
    "from transformers import GPT2LMHeadModel, GPT2Tokenizer, GPT2Model\n",
    "\n",
    "tokenizer = GPT2Tokenizer.from_pretrained(\"gpt2\")\n",
    "model_headless = GPT2Model.from_pretrained(\"gpt2\")\n",
    "model_tied_unembed = GPT2LMHeadModel.from_pretrained(\"gpt2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input token IDs: tensor([[ 8291, 16354, 16326]])\n"
     ]
    }
   ],
   "source": [
    "input_string = \"Transformer tokens\"\n",
    "tokens = tokenizer(input_string, return_tensors=\"pt\")\n",
    "token_ids = tokens.input_ids\n",
    "print(\"Input token IDs:\", token_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 3, 50257])\n",
      "torch.Size([1, 50257])\n",
      "logits\t tensor([[-102.2224, -102.7583, -103.2500, -103.6413, -103.6857, -103.7877,\n",
      "         -103.8186, -103.8804, -103.8891, -103.9821]])\n",
      "ids\t tensor([[389,  13,  11, 357, 287, 284, 198, 460, 326, 481]])\n",
      "\n",
      "Output probability distributions for varying temperature (top-k=10)\n",
      "tok_id\t token\t   T=1.0   T=0.5   T=1.5\n",
      "389\t' are'     29.6%   56.5%   21.6%\n",
      "13\t'.'        17.3%   19.4%   15.1%\n",
      "11\t','        10.6%    7.2%   10.9%\n",
      "357\t' ('        7.2%    3.3%    8.4%\n",
      "287\t' in'       6.8%    3.0%    8.1%\n",
      "284\t' to'       6.2%    2.5%    7.6%\n",
      "198\t'\\n'        6.0%    2.3%    7.4%\n",
      "460\t' can'      5.6%    2.1%    7.1%\n",
      "326\t' that'     5.6%    2.0%    7.1%\n",
      "481\t' will'     5.1%    1.7%    6.7%\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    outputs = model_tied_unembed(tokens.input_ids, use_cache=False)\n",
    "logits = outputs.logits\n",
    "print(logits.shape)\n",
    "\n",
    "# logits for the last token:\n",
    "final_token_logits = logits[:, -1, :]\n",
    "print(final_token_logits.shape)\n",
    "\n",
    "top_10_logits, top_10_token_indices = torch.topk(final_token_logits, 10, dim=-1)\n",
    "print('logits\\t', top_10_logits)\n",
    "print('ids\\t', top_10_token_indices)\n",
    "\n",
    "softmax = torch.nn.Softmax(dim=-1)\n",
    "\n",
    "probs = softmax(top_10_logits)\n",
    "\n",
    "cold_temp = 0.5\n",
    "top_10_logits_cold = top_10_logits / cold_temp\n",
    "probs_cold = softmax(top_10_logits_cold)\n",
    "\n",
    "hot_temp = 1.5\n",
    "top_10_logits_hot = top_10_logits / hot_temp\n",
    "probs_hot = softmax(top_10_logits_hot)\n",
    "\n",
    "print('\\nOutput probability distributions for varying temperature (top-k=10)')\n",
    "print(f'tok_id\\t token\\t   T=1.0   T=0.5   T=1.5')\n",
    "for i in range(10):\n",
    "    tok_id = top_10_token_indices[0][i]\n",
    "    token = repr(tokenizer.decode(tok_id))  # using repr() to escape e.g. new lines\n",
    "    prob = probs[0][i]*100\n",
    "    prob_cold = probs_cold[0][i]*100\n",
    "    prob_hot = probs_hot[0][i]*100\n",
    "    print(f'{tok_id.item()}\\t{token:10s}{prob:5.1f}%  {prob_cold:5.1f}%  {prob_hot:5.1f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "odict_keys(['logits'])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CausalLMOutputWithCrossAttentions(loss=None, logits=tensor([[[ -27.1873,  -26.1459,  -28.7534,  ...,  -35.2827,  -35.1941,\n",
       "           -27.1063],\n",
       "         [ -72.1955,  -68.4561,  -69.9005,  ...,  -80.4494,  -76.7446,\n",
       "           -70.7487],\n",
       "         [-107.4842, -106.8489, -110.9719,  ..., -119.1011, -116.9099,\n",
       "          -108.4834]]]), past_key_values=None, hidden_states=None, attentions=None, cross_attentions=None)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(outputs.keys())\n",
    "outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transformer tokens are not available for use in the game.\n",
      "\n",
      "The following table lists the tokens that can be used in the game.\n",
      "\n",
      "Token Name Description 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17\n"
     ]
    }
   ],
   "source": [
    "# autoregressive test\n",
    "with torch.no_grad():\n",
    "    full_gen_output = model_tied_unembed.generate(inputs=tokens.input_ids,\n",
    "                                     attention_mask=tokens.attention_mask,\n",
    "                                     use_cache=False,\n",
    "                                     pad_token_id=tokenizer.eos_token_id,\n",
    "                                     max_length=50)\n",
    "\n",
    "generated_text = tokenizer.decode(full_gen_output[0])\n",
    "print(generated_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token 1: torch.Size([768]) min -0.5692750215530396 max 0.3343436121940613\n",
      "Token 1: torch.Size([768]) min -0.5692750215530396 max 0.3343436121940613\n",
      "Token 2: torch.Size([768]) min -0.6863736510276794 max 0.3896985948085785\n",
      "Token 2: torch.Size([768]) min -0.6863736510276794 max 0.3896985948085785\n",
      "Token 3: torch.Size([768]) min -0.42473170161247253 max 0.6322500109672546\n",
      "Token 3: torch.Size([768]) min -0.42473170161247253 max 0.6322500109672546\n"
     ]
    }
   ],
   "source": [
    "embedding_layer = model_headless.get_input_embeddings()\n",
    "\n",
    "for i, tok in enumerate(token_ids.flatten()):\n",
    "    # these are identical...\n",
    "    embed1 = embedding_layer(tok)\n",
    "    embed2 = model_headless.wte.weight[tok]\n",
    "    for e1, e2 in zip(embed1, embed2):\n",
    "        if e1 != e2:\n",
    "            print('mismatch!')\n",
    "    print(f'Token {i+1}: {embed1.shape} min {torch.min(embed1)} max {torch.max(embed1)}')\n",
    "    print(f'Token {i+1}: {embed2.shape} min {torch.min(embed2)} max {torch.max(embed2)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(-1.2698, grad_fn=<MinBackward1>) tensor(1.7852, grad_fn=<MaxBackward1>)\n"
     ]
    }
   ],
   "source": [
    "global_min = float('inf')\n",
    "global_max = float('-inf')\n",
    "\n",
    "for tok_id in range(50257):\n",
    "  embed = embedding_layer(torch.tensor(tok_id))\n",
    "  if torch.min(embed) < global_min:\n",
    "    global_min = torch.min(embed)\n",
    "  if torch.max(embed) > global_max:\n",
    "    global_max = torch.max(embed)\n",
    "print(global_min, global_max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPT-2 token embeddings: torch.Size([50257, 768])\n",
      "min -1.26982 max 1.78516 mean 0.00038\n",
      "\n",
      "GPT-2 position embeddings: torch.Size([1024, 768])\n",
      "min -4.53811 max 4.06531 mean -0.00068\n"
     ]
    }
   ],
   "source": [
    "token_embeddings = model_headless.wte.weight\n",
    "position_embeddings = model_headless.wpe.weight\n",
    "\n",
    "te_min = torch.min(token_embeddings).item()\n",
    "te_max = torch.max(token_embeddings).item()\n",
    "te_mean = torch.mean(token_embeddings).item()\n",
    "pe_min = torch.min(position_embeddings).item()\n",
    "pe_max = torch.max(position_embeddings).item()\n",
    "pe_mean = torch.mean(position_embeddings).item()\n",
    "\n",
    "# format with precision .5f\n",
    "p = lambda x: f'{x:.5f}'\n",
    "\n",
    "print('GPT-2 token embeddings:',    token_embeddings.shape)\n",
    "print(f'min {p(te_min)} max {p(te_max)} mean {p(te_mean)}\\n')\n",
    "\n",
    "print('GPT-2 position embeddings:', position_embeddings.shape)\n",
    "print(f'min {p(pe_min)} max {p(pe_max)} mean {p(pe_mean)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "displaying embeddings for token id 8291 at pos 0\n",
      "te: tensor([ 0.129,  0.055,  0.176, -0.061, -0.118,  0.041, -0.217, -0.078, -0.123])\n",
      "pe: tensor([-0.019, -0.197,  0.004,  0.011,  0.064, -0.105,  0.037, -0.168, -0.049])\n",
      "ie: tensor([ 0.110, -0.142,  0.180, -0.050, -0.054, -0.064, -0.180, -0.246, -0.173])\n",
      "input embed min -4.560337543487549, input embed max 3.768101453781128\n",
      "displaying embeddings for token id 16354 at pos 1\n",
      "te: tensor([ 0.087, -0.009,  0.285,  0.097, -0.074, -0.266, -0.274, -0.176, -0.077])\n",
      "pe: tensor([ 0.024, -0.054, -0.095, -0.013, -0.010,  0.031,  0.051,  0.185,  0.044])\n",
      "ie: tensor([ 0.111, -0.062,  0.190,  0.084, -0.084, -0.235, -0.223,  0.009, -0.033])\n",
      "input embed min -1.4507211446762085, input embed max 1.5265089273452759\n",
      "displaying embeddings for token id 16326 at pos 2\n",
      "te: tensor([ 0.132, -0.019,  0.016, -0.122, -0.229,  0.189, -0.310,  0.018, -0.087])\n",
      "pe: tensor([ 0.004, -0.085,  0.055, -0.005, -0.026,  0.015,  0.026,  0.059, -0.005])\n",
      "ie: tensor([ 0.136, -0.103,  0.071, -0.127, -0.255,  0.204, -0.284,  0.077, -0.092])\n",
      "input embed min -1.2831257581710815, input embed max 1.4215716123580933\n"
     ]
    }
   ],
   "source": [
    "torch.set_printoptions(sci_mode=False, precision=3)\n",
    "\n",
    "hex_values = []\n",
    "for pos, tok in enumerate(token_ids[0]):\n",
    "    print(f'displaying embeddings for token id {tok} at pos {pos}')\n",
    "    te = model_headless.wte.weight[tok].detach()\n",
    "    pe = model_headless.wpe.weight[pos].detach()\n",
    "    ie = te+pe\n",
    "    print(f'te: {te[0:9]}')\n",
    "    print(f'pe: {pe[0:9]}')\n",
    "    print(f'ie: {ie[0:9]}')\n",
    "    print(f'input embed min {torch.min(ie)}, input embed max {torch.max(ie)}')\n",
    "\n",
    "    components = list(range(128-3)) + [-3, -2, -1] # inspect first 125 and last 3\n",
    "\n",
    "    hex_values.append([])\n",
    "\n",
    "    for component in components:\n",
    "        # convert each component's magnitude to a shade of gray\n",
    "\n",
    "        magnitude = min(max(ie[component].item(), -3), 3)  # floor, ceiling of -3, 3\n",
    "        normed = (magnitude + 3) / 6\n",
    "        eight_bit_scale = round(normed * 255)\n",
    "        # print(f'{component}: {eight_bit_scale}')\n",
    "        hex_values[pos].append(component)\n",
    "\n",
    "torch.set_printoptions(profile=\"default\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjcAAAHACAYAAABeV0mSAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjAsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvlHJYcgAAAAlwSFlzAAAPYQAAD2EBqD+naQAANupJREFUeJzt3Qm8zdXex/GfeQqFOGYyzzJlaKCIkofcW1IyK11kyO2mepQmuTLUJfSU6UppQDcVnRQqJEOJW8ZyKFNlLvN5Xt/V3efuc5xznHnvs87n/Xr9X+z/ntbeB/+vtX5rrWzR0dHRBgAA4InsoW4AAABAWiLcAAAArxBuAACAVwg3AADAK4QbAADgFcINAADwCuEGAAB4hXADAAC8QrgBAABeIdwAAACvZOlws2LFCuvQoYOVKlXKsmXLZgsXLkz2a2j3iueee86qVq1qefLksdKlS9vTTz+dLu0FAAAXl9OysBMnTli9evWsd+/e1rlz5xS9xuDBg+3DDz90AadOnTr266+/ugMAAIRGNjbO/IN6bhYsWGCdOnWKOXfq1Cl75JFH7LXXXrPDhw9b7dq1bcyYMdayZUt3/7fffmt169a1TZs2WbVq1ULYegAAEJClh6UuZuDAgbZq1Sp7/fXXbePGjXbbbbdZu3btbNu2be7+d99916644gpbtGiRVaxY0SpUqGB9+/al5wYAgBAi3CQgKirKZsyYYW+++aZdc801VqlSJRs+fLhdffXV7rzs3LnTdu3a5R4ze/Zsmzlzpq1bt87+/Oc/h7r5AABkWVm65iYx33zzjZ07d84VCgfTUFXRokXd78+fP+9uK9gEHvfKK69Yw4YNbcuWLQxVAQAQAoSbBBw/ftxy5MjhemL0a7BLLrnE/VqyZEnLmTNnrABUo0aNmJ4fwg0AABmPcJOAK6+80vXcHDhwwA1LxadFixZ29uxZ27Fjhxu2kq1bt7pfy5cvn6HtBQAAf8jSs6XUO7N9+/aYMDN+/Hhr1aqVFSlSxMqVK2fdunWzzz//3MaNG+fuP3jwoC1dutTNkGrfvr0blmrcuLHryZk4caK7PWDAACtUqJCbHg4AADJelg43y5Ytc2Emrh49erji4DNnzthTTz3lamp+/PFHK1asmDVt2tRGjRrl1rSRn376yQYNGuTCTIECBeymm25yYUgBCQAAZLwsHW4AAIB/mAoOAAC8QrgBAABeCelsqSlTprjjhx9+cLdr1aplI0eOdHUr8VEdTK9evWKd02aVJ0+eTPJ7quhXdTIFCxZ0Wy4AAIDwpyqaY8eOuc2us2fPHr7hpkyZMvbss89alSpVXKNnzZplHTt2tA0bNrigEx/NRNICeQHJDSgKNmXLlk112wEAQMbbvXu3yw9hG246dOgQ6/bTTz/tenJWr16dYLhRmImIiEjxe6rHJvDlKCgBAIDwd/ToUdc5EbiOZ4pF/LRgnvZoOnHihDVr1izRtWm0QJ6Glxo0aGDPPPNMgkFItD2CjgB1aYmCDeEGAIDMJSkjNtnDYQ8nLYKn2pn+/fvbggULrGbNmvE+VtsZTJ8+3d555x2bM2eOCzjNmze3PXv2JPj6o0ePtsKFC8ccDEkBAOC3kK9zc/r0abcP05EjR+ytt96yl19+2ZYvX55gwAmmRfa0l1PXrl3tySefTFLPTaBbS+9Hzw0AAJmDrt/qpEjK9Tvkw1K5c+e2ypUru99rN+0vv/zSnn/+eZs2bdpFn5srVy63LUJgC4X4qEdIBwAAyBpCHm7i0lBTcE/Lxep0NKx18803p3u7ACCj6N829UwDWU3u3LkvOs077MPNiBEj3Jo22qRShb5z5851+z0tWbLE3d+9e3crXbq0q5uRJ554wu3tpJ6ew4cP29ixY23Xrl3Wt2/fUH4MAEgTqhLYt2+f+/cNyIqyZ89uFStWdCEn04abAwcOuACzd+9eN46m3bYVbNq0aePuVy1OcII7dOiQ9evXz/3lv+yyy9ww1sqVK5NUnwMA4S4QbIoXL2758+dnoVFkKef/s8iuMoE6PVLz5z/kBcXhXJAEABk5FLV161YXbIoWLRrq5gAhoWuzAo5GaFRXm9Lrd8inggMA/pj9KeqxAbKq3P8ZjlLYTw3CDQCEEYaikJVlS6M//4QbAADgFcINACDD/fDDD+5/6V999ZX5oGfPntapU6c0f13NINb3lNgMupkzZ9qll14ac/vxxx+3+vXrW1YWduvcAABimxC5NcPea2ibqmk2hPDYY4+5C204admypVsFP657773Xpk6daj4YPny4DRo0yLIywg0AIEU0ZTdg3rx5NnLkSNuyZUvMOe0bGI60pIjWTQvmUyH3JZdcErbffUZhWAoAkCIRERExh6boqicncFtT2sePH29lypRxW+BomGTx4sUJvpZmx/Tu3duqV6/u1jgTbZLcoEEDy5s3r11xxRU2atQoO3v2bMxz9H7aj/DWW2914aRKlSr2r3/966Lt1mOD264jMLU4MFz2xhtv2DXXXGP58uWzxo0bu2n62h6oUaNGLjhoAdqDBw9e8Npq4+WXX+5eT5tBa//E4HVctCitFqnT69arV8/tqRjs/ffft6pVq7r7W7Vq5doT3zCU1oHR59Bn/+WXX2Ld/3icYanAkNlzzz1nJUuWdEsNDBgwINYq2Aqq7du3d++r9mlR3QoVKtjEiRPd/Vo1Rq+r99XPs1SpUnb//fdbuCLcAADSnPYIHDdunLugbty40dq2bWv/8z//Y9u2bbvgsdpy57bbbnP1N59++qm7gOpXLfI6ePBg+/e//+32G9RF/emnn74gTNx+++3uPbQVz1133WW//vprqtuvIbVHH33U1q9fbzlz5rQ777zTHnzwQfe51DbtaaieqmBLly61b7/91tXJvPbaazZ//nzXvgAFm9mzZ7vhr82bN9vQoUOtW7duMcNku3fvts6dO1uHDh3cd6HV9x966KFY7/HFF19Ynz59bODAge4xCkBPPfXURT/PJ598Yjt27HC/zpo1y32XOgL0XWt9GbX97bfftpdeeskttBugcxMmTHA/B/0MFy5caHXq1LFwRbgBkKVlZD1LVqJQ87e//c3uuOMOq1atmo0ZM8b1JgR6AgKOHz/uegzUC6ILr3o9RKFAF/YePXq4XhutXP/kk09esKmyeiW6du3qFn175pln3OutWbMm0ba9+OKLMUM3gePVV1+9oG5FgaxGjRouYK1bt87+93//11q0aOE2bFbAUHvjrtEyffp0q1WrlvtMGvp64YUXYvZMVPt0v15Xn0ltV7gJfKYpU6ZYpUqVXCjUd6agpscEU7hq166dC1rq4VHviV7vYi677DKbNGmS6xm75ZZbXPsUxuS7776zjz76yP7v//7PrrrqKtdbph6x33//Peb56k1TD1fr1q1d+GzSpIkb3gtX1NwAANKUVpJVL4CCQDDd/vrrr2OdUzDR0NXHH3/shkQC9LjPP/88Vk+Nhq5Onjxpv/32W0yNjLbtCShQoIAbDgrucYiPQsMjjzwS61yJEiVi3Q5+3cB9wT0VOhf3fTTMFFy706xZMxe21COjX9XuwPZCARq2UlgS9fooXATTawTTYzQUFfcxiQ35iQJXjhw5LEDDU9p4WlQnpd4phZoAhUUFogD1rCmYKpQpXKmXTD1Mel44Cs9WAQCyBF0k58yZY6tWrbLrr78+5rzCgHpvNEwTl2pwAuIu0a96GfWUJEb1Qbp4Jyb4dQOzwuKeu9j7BNPnkffee89tCB1MNSzpLVcKvqdgZcuWdSFIPTyRkZH2l7/8xW1erSG1uK8dDgg3AIA0pd4TFZyq5+W6666LOa/bGs4Idt9991nt2rVdPY4u/IHHqxdBF9OLhZBwot4mDeUEeqBWr17thrwUDIoUKeJCjIZ3gr+TYBoCi1sQrdeI+xjV3ST2mOTSEJgKtTds2OA2pBbVFGmz6mD6XOqt0aGCZA1xqfcnuMcnXBBuAABp7q9//asrylUNiWptZsyY4Qpg49a2iNZk0ZCTakE++OADu/rqq12xrm6rvuPPf/6zZc+e3YWHTZs2JamANjEaHtIO7MEUPIKHYVJCQ0yqxVEhsmY56fOr8FdtL1iwoKvjURGxekz0GbUBpAKfwqBqizS7SvU2+u5UTKw6n+CiX1GNjYb3VNPUsWNHW7JkyUWHpC5GIUW1NPfcc4+r+1FPzAMPPODCTKDXSu3Qz0jDZhp6U2+b7i9fvryFIwqKAQBpThfhYcOGuYukalV0AVavhKZrx2fIkCFuGErDVCtXrnRFsosWLbIPP/zQTcVu2rSpm62TFhdTFc6q5iT4UO1Pat1www3u81177bXWpUsX1xsVvIihCqJVlKxZU+qBUe2Keqs09VoU5DQrSTORVL+jWVUqQg6m70HtV2GxHqPvR2EqtWbPnu3qiNR21fSoWFiBLDAEqBWQ9b4KVqpH0vDUu+++G7Y72GeL1uT1LCQ5W6YDyBqzpZKzKm96UaHs999/7y50wTUlQCjs2bPHDacpxCi0hcPfg+RcvxmWApDlBaaDh0PIAULh448/dkXP6mXTgn6aaq5F/NSTkxkRbgBkSaxvA/yXVit++OGHbefOnW44qnnz5q4+KhxnQiUF4QYAgCyubdu2SVoMMLOgoBgAAHiFcAMAALxCuAEAAF4h3AAAAK8QbgAAgFcINwAAwCuEGwBAWFq2bJnb2+jw4cOJPk6LzU2cONEyI+1Bpc+ofbfSWsuWLd22Fsn57tQWbf+Q2bHODQCEu09GZ9x7tRqRrIf37NnTZs2a5X6vBd+0P1L37t3dgnA5c6buEqOF5LRarpbcD2zeqIt13LDz5ZdfWoECBSy9g1arVq3ivU9tjIiIMB/s3bs31RuIhgPCDQAgVbQBpHb9PnXqlL3//vs2YMAAF3RGjEheUIord+7cSQoNl19+uWWULVu2XLCvUfHixc0XEZ6ENIalAACpkidPHndR1I7d9913n7Vu3drtAC6HDh1yPTnqDcifP7/ddNNNtm3btpjn7tq1yzp06ODuV+9LrVq1XECKOyyl3/fq1cttmqhzOgI7bscdWomKirKOHTvaJZdc4oLI7bffbvv374+5X8+rX7++/fOf/3TPVc/QHXfcYceOHbvoZ1WQ0WcNPrJnzx7Ti9WpUye3k7d22NZO2k888YSdPXvW/vrXv1qRIkWsTJkyLgjG9d1337meKm0WWbt2bVu+fHms+zdt2uS+O30mvfbdd99tP//8c8z9J06ccN+z7i9ZsqSNGzfugvc4cOCA+67z5cvnNqbU9gpxBQ9LBYbM5s+f73qt9PPTTuSrVq2K9RztFq5NNnW/dhQfP368++wBX3/9tXu+tnXQz6Nhw4a2du1aS0+EGwBAmtLF8/Tp0zEXfF3IFHZ0UYyOjrabb77Z7WUk6uVRj8+KFSvsm2++sTFjxrgLdFy68CvA6OKooRMdw4cPv+Bx58+fd8Hm119/dQEhMjLS7ZfUpUuXWI/bsWOHu4gvWrTIHXrss88+myYbUP7000/u8+gi/9hjj9ktt9ziwtsXX3xh/fv3t3vvvdftuh1M4eeBBx6wDRs2WLNmzVwI+eWXX9x9CnfXX3+9XXnlle67XLx4sQtrCm3Bz9dneOedd+zDDz90YXD9+vWx3kM/i927d9snn3xib731lr344osu8FzMI4884r5r1QVVrVrVunbt6gKbfP755+4zDR482N3fpk0be/rpp2M9/6677nKhTsOH69ats4ceeijd96xiWAoAkCYUXJYuXWpLliyxQYMGuR4ahRpdABVORL0F+l++gsVtt93meln+9Kc/ud2o5YorrkhwiEo9LOpJSGzoRO+vkPT999+795HZs2e7HiFdXBs3bhwTglTDo94EUU+Inhv3whyXLtLB1Fu1efPmmNvqnXnhhRdcb061atXs73//u/3222+uBkk0VKcQ9dlnn7neooCBAwe670GmTJniAswrr7zidueeNGmSCzbqEQqYPn26+3xbt261UqVKucfOmTPHbrjhBne/6qCC26rHffDBB7ZmzZqY70DPqVGjhl2Mgk379u3d70eNGuW+y+3bt1v16tXtH//4h+tRCgRNhZ+VK1e6wBign7HClx4vVapUsfRGuAEApIouZOptUW+MQsOdd97phn4UFlRUfNVVV8U8tmjRou6i/+2337rb999/vxvKUm+DhrN0ga9bt26K26LX1UU/EGykZs2abphE9wUu7BqOCgQb0VBOUnoxPv3001jPi9sDoQt/YJhKNISkYaaAHDlyuO8g7nuptyZA31mjRo1iviMN66i3Jb4eLfVA/f77766nLPh7LlKkiPueg78Xva6GhAIUNoKHjxIS/PPQ9yRqv56vGiQNRQVr0qRJrHAzbNgw69u3rxsG1M9YobZSpUqWnhiWAgCkiuopNCShnhpdaNVrkNTZS7roadhIPSfqcdFFXb0B6S1uKFGPkILZxahWpXLlyjGHem4u9ropfa+A48ePu2EqfcfBh77va6+91tJbrqD2q+2SnPYr6Kp3S70/GrZT2FywYIGlJ8INACBVFGR0odc08ODp3xryUG2Gak0CVEei/+3rAhegXhbVbahwVXUnKlBNaGjq3LlzibZF76m6Eh0B//73v13dSvB7hpvVq1fH/F7fmWpTAkNGDRo0cOFAvU3BwUqHvnv1giiABH/Phw4dckNRAeplCbxugH4OF1tD6GLUO6ThvmBxbweGq4YOHep66Dp37hxvUXVaItwAANKFaitU3NuvXz9XY6LhlW7dulnp0qXdedG6NarRUY2MCmA1/JJQHYgu7urF0HCXZgqpliUuDXuofkdFrHo91ZhoFtF1113neoVSS8Mx+/bti3UEiqNTY/Lkya43Q7OmVGStcNK7d293n26rQFqFvAoOGorSd6bZYwp7Gq7q06ePq2tRz8imTZtc8XDw8JhCiKbsq5hZIUghR71mKv5ODdVWaXabiqfVkzRt2jRX2xPo4VFPnuqJVOCsmXGqv9JnSEqtT2oQbgAA6Ub/Q1edh2YMqa5ERce6GAaGOnRx1sVbFztdfPU/fM3iiY+KktXDo5lPWttGxbpx6aKqGUOanaQhG4UdFSnPmzcvTT6PQoLqToKP4N6QlFKRsQ5NtVYQVCF2sWLF3H0qGFYo0Hd14403uvCmUKh6mUCAGTt2rF1zzTVu+Kp169Z29dVXx6qvCfws9FoKeuo9ueeee1K9Rk+LFi1s6tSpLtyo7SqEVg+NprQHaozUW6eAqZ+tZnipAFmFyekpW7T+pGUhR48edRX3Wish7kJMALKOCZH/7bIPGNqmqoXKyZMnXe+FajoCFwYgM+rXr5/rgVLxdVr+PUjO9ZvZUgAAIMWee+45t76N6n80JKWC8oR63zIK4QYA4vTmhLIHB8hs1qxZ44YItcKzhgC1zo/qeUKJcAMAAFLsjTfesHBDQTEAAPAK4QYAwkgWm+MBpMuf/5CGG+2foWWdVfWsQ9MEVYyUmDfffNMtRqQqak2HC+weCwCZWWBqdHxrtwBZxen/bLiqKeSZtuZGm3ppXr8WelJaU4W1FnbSrqjanyMubcalRYxGjx7t1kyYO3eu215eCzUF790BAMmdBh5q+sdc65YE9hzKnz9/zEJoQFZw/vx5O3jwoPuzH7zStRfr3GizLy1GpNUW49LCTSdOnIi1IVfTpk2tfv36bhGhpGCdGwAXCzehmi2lf4614m1ql8QHMistSqg1brTVRlyZcp0brbyoISeFl+DdUYOtWrXK7S4arG3btrZw4cIEX/fUqVPuCP5yACAcqadGK95q1di0WNIfyGwUaoK3jUipkIcb7QKrMKNVCbU/hvbWSGhzM/2PRtvHB9NtnU+IhrDSe5lnAEjrIarU1hwAWVnIZ0tpnw5t3a6NvO677z7r0aOH28E1rYwYMcJ1YQWO4J1iAQCAf3KGQxeUtm0XbfKl3UKff/55t7NoXBEREbZ///5Y53Rb5xOSJ08edwAAgKwh5D038VVLB9fIBNPwlba6DxYZGZlgjQ4AAMh6QtpzoyEjbX1erlw5tyeFpnYvW7bMlixZ4u7XFumlS5d2dTMyePBgt1X7uHHjrH379vb666/b2rVr7aWXXgrlxwAAAGEkpOFG6zkowOzdu9dN79KCfgo22l1UoqKiYlVNN2/e3AWgRx991B5++GG3Po5mSrHGDQAACNt1btIb69wACNd1bgCkzfU77GpuAAAAUoNwAwAAvEK4AQAAXiHcAAAArxBuAACAVwg3AADAK4QbAADgFcINAADwCuEGAAB4hXADAAC8QrgBAABeIdwAAACvEG4AAIBXCDcAAMArhBsAAOAVwg0AAPAK4QYAAHiFcAMAALxCuAEAAF4h3AAAAK8QbgAAgFcINwAQx4TIraFuAoBUINwAAACvEG4AAIBXCDcAAMArhBsAAOAVwg0AAPAK4QYAAHiFcAMAALxCuAEAAF4h3AAAAK/kDHUDACCjsPIwkDXQcwMAALxCuAEAAF4h3AAAAK8QbgAAgFcINwAAwCuEGwAA4BXCDQAA8ArhBgAAeIVwAwAAvBLScDN69Ghr3LixFSxY0IoXL26dOnWyLVu2JPqcmTNnWrZs2WIdefPmzbA2AwCA8BbScLN8+XIbMGCArV692iIjI+3MmTN244032okTJxJ9XqFChWzv3r0xx65duzKszQAAILyFdG+pxYsXX9Arox6cdevW2bXXXpvg89RbExERkQEtBAAAmU1Y1dwcOXLE/VqkSJFEH3f8+HErX768lS1b1jp27GibN2/OoBYCAIBwFzbh5vz58zZkyBBr0aKF1a5dO8HHVatWzaZPn27vvPOOzZkzxz2vefPmtmfPnngff+rUKTt69GisAwAA+Cukw1LBVHuzadMm++yzzxJ9XLNmzdwRoGBTo0YNmzZtmj355JPxFi2PGjUqXdoMAADCT1j03AwcONAWLVpkn3zyiZUpUyZZz82VK5ddeeWVtn379njvHzFihBvuChy7d+9Oo1YDAIBwFNKem+joaBs0aJAtWLDAli1bZhUrVkz2a5w7d86++eYbu/nmm+O9P0+ePO4AAABZQ85QD0XNnTvX1c9orZt9+/a584ULF7Z8+fK533fv3t1Kly7thpfkiSeesKZNm1rlypXt8OHDNnbsWDcVvG/fvqH8KAAAIEyENNxMmTLF/dqyZctY52fMmGE9e/Z0v4+KirLs2f87enbo0CHr16+fC0KXXXaZNWzY0FauXGk1a9bM4NYDAIBwlC1aY0NZiGZLqWdI9TdaDBBA1jEhcmuSHzu0TdV0bQuA9Lt+h0VBMQAAQFoh3AAAAK8QbgAAgFcINwAAwCuEGwAA4BXCDQAA8ArhBgAAeIVwAwAAvEK4AQAAXiHcAAAArxBuAACAVwg3AADAK4QbAADgFcINAADwCuEGAAB4hXADAAC8QrgBgHhMiNzqDgCZD+EGAAB4hXADAAC8QrgBAABeIdwAAACvEG4AAIBXCDcAAMArOUPdAABIb0zpBrIWem4AAIBXCDcAAMArhBsAAOAVwg0AAPAK4QYAAHiFcAMAALxCuAEAAF4h3AAAAK8QbgAAgFcINwAAwCuEGwAA4BXCDQAA8ArhBgAAeIVwAwAAvJKicLNz5860bwkAAECowk3lypWtVatWNmfOHDt58mRatAMAACB04Wb9+vVWt25dGzZsmEVERNi9995ra9asSZsWAQAAZHS4qV+/vj3//PP2008/2fTp023v3r129dVXW+3atW38+PF28ODB1LQJAAAgNAXFOXPmtM6dO9ubb75pY8aMse3bt9vw4cOtbNmy1r17dxd6EjN69Ghr3LixFSxY0IoXL26dOnWyLVu2XPR99X7Vq1e3vHnzWp06dez9999PzccAAAAeSVW4Wbt2rf3lL3+xkiVLuh4bBZsdO3ZYZGSk69Xp2LFjos9fvny5DRgwwFavXu2ec+bMGbvxxhvtxIkTCT5n5cqV1rVrV+vTp49t2LDBBSIdmzZtSs1HAQAAnsgWHR0dndwnKcjMmDHD9bLcfPPN1rdvX/dr9uz/zUp79uyxChUq2NmzZ5P8uhrOUg+OQs+1114b72O6dOniws+iRYtizjVt2tQNlU2dOvWi73H06FErXLiwHTlyxAoVKpTktgHIvCZEbk3xc4e2qZqmbQGQMsm5fudMyRtMmTLFevfubT179nS9NvFRSHnllVeS9bpqsBQpUiTBx6xatcoVMgdr27atLVy4MN7Hnzp1yh3BXw4AAPBXisLNtm3bLvqY3LlzW48ePZL8mufPn7chQ4ZYixYtXGFyQvbt22clSpSIdU63dT6hup5Ro0YluR0AACAL1txoSEpFvXHp3KxZs1LUENXeqG7m9ddft7Q0YsQI1yMUOHbv3p2mrw8AADwIN+oNKVasWLxDUc8880yyX2/gwIGuhuaTTz6xMmXKJPpYrauzf//+WOd0W+fjkydPHjc2F3wAAAB/pSjcREVFWcWKFS84X758eXdfUqmWWcFmwYIF9vHHH8f7mnE1a9bMli5dGuucZlrpPAAAQIrCjXpoNm7ceMH5r7/+2ooWLZqsoSht4TB37ly31o3qZnT8/vvvMY/RejkaWgoYPHiwLV682MaNG2ffffedPf74425KukISAABAisKN1pm5//773TDSuXPn3KGeFwWPO+64I1mzrlQH07JlSzfrKnDMmzcv5jHqCQpeDLB58+YuDL300ktWr149e+utt9xMqcSKkAEAQNaRonVuTp8+bXfffbcrINYqxYHZTupl0VozmikVrljnBsh6WOcGyPzSfZ0bhRf1rjz55JNuKCpfvnxuGwTV3AAAAIRSisJNQNWqVd0BAACQqcONamxmzpzpZi0dOHDADUkFU/0NAABApgk3KhxWuGnfvr0r5M2WLVvatwwAACCjwo1WEX7jjTfcZpkAAACZfiq4CoorV66c9q0BAAAIRbh54IEH7Pnnn3crDAOAz1IzjRxAJhqW+uyzz9wCfh988IHVqlXLcuXKFev++fPnp1X7AAAA0j/cXHrppXbrrbem5KkAAADhF25mzJiR9i0BAAAIVc2NnD171j766CObNm2aHTt2zJ376aef7Pjx42nRLgAAgIzrudm1a5e1a9fObWp56tQpa9OmjdvVe8yYMe629pcCAADIND03WsSvUaNGdujQIbevVIDqcLRqMQAAQKbqufn0009t5cqVF+z+XaFCBfvxxx/Tqm0AAAAZ03OjvaS0v1Rce/bsccNTAAAAmSrc3HjjjTZx4sSY29pbSoXEjz32GFsyAACAzDcsNW7cOGvbtq3VrFnTTp48aXfeeadt27bNihUrZq+99lratxIAUogVhoGsJ0XhpkyZMvb111+7DTQ3btzoem369Oljd911V6wCYwAAgEwRbtwTc+a0bt26pW1rAAAAQhFuZs+enej93bt3T2l7AAAAMj7caJ2bYGfOnLHffvvNTQ3Pnz8/4QYAAGSu2VJavC/4UM3Nli1b7Oqrr6agGAAAZM69peKqUqWKPfvssxf06gAAAGTKcBMoMtbmmQAAAJmq5uZf//pXrNvR0dG2d+9emzRpkrVo0SKt2gYAAJAx4aZTp06xbmuF4ssvv9yuv/56t8AfAABApgo32lsKAADA+5obAACATNlzM2zYsCQ/dvz48Sl5CwAAgIwLNxs2bHCHFu+rVq2aO7d161bLkSOHNWjQIFYtDgAAQNiHmw4dOljBggVt1qxZdtlll7lzWsyvV69eds0119gDDzyQ1u0EAABIv5obzYgaPXp0TLAR/f6pp55ithQAAMh84ebo0aN28ODBC87r3LFjx9KiXQAAABkXbm699VY3BDV//nzbs2ePO95++23r06ePde7cOWUtAQAACFXNzdSpU2348OF25513uqJi90I5c7pwM3bs2LRoFwAAQMaFm/z589uLL77ogsyOHTvcuUqVKlmBAgVS1goAAIBwWMRP+0np0I7gCjbaYwoAACDThZtffvnFbrjhBqtatardfPPNLuCIhqWYBg4AADJduBk6dKjlypXLoqKi3BBVQJcuXWzx4sVp2T4AAID0r7n58MMPbcmSJVamTJlY5zU8tWvXrrRqGwAAQMb03Jw4cSJWj03Ar7/+anny5EnJSwIAAIQu3GiLhdmzZ8faQ+r8+fP297//3Vq1apXk11mxYoXbyqFUqVLuNRYuXJjo45ctW+YeF/fYt29fSj4GAADwUIqGpRRiVFC8du1aO336tD344IO2efNm13Pz+eefJ6sHqF69eta7d+9kLf63ZcsWK1SoUMzt4sWLJ/szAAAAP6Uo3NSuXdvtAj5p0iS3gebx48ddOBkwYICVLFkyya9z0003uSO5FGYuvfTSZD8PAAD4L9nhRisSt2vXzq1S/Mgjj1go1K9f306dOuVC1uOPP24tWrQISTsAAIAH4UZTwDdu3GihoF4hhapGjRq5cPPyyy9by5Yt7YsvvrAGDRrE+xw9Tkfwpp8AAMBfKSoo7tatm73yyiuW0apVq2b33nuvNWzY0Jo3b27Tp093v06YMCHB54wePdoKFy4cc5QtWzZD2wwAADJBzc3Zs2ddsPjoo49c0Ii7p9T48eMtozRp0sQ+++yzBO8fMWKEDRs2LFbPDQEHQHJMiNzqfh3apmqomwIgrcPNzp07rUKFCrZp06aYYSAVFgfT1OyM9NVXXyVaxKx1d1h7BwCArCNZ4UYrEGsfqU8++SRmu4UXXnjBSpQokaI31yyr7du3x9z+/vvvXVgpUqSIlStXzvW6/PjjjzFr6kycONEqVqxotWrVspMnT7qam48//titmAwAAJDscBN31+8PPvjArVWTUlonJ3jRv8DwUY8ePWzmzJkuSGn/qgCtqaONORV4tEJy3bp13dBYchYOBAAAfktRzU1CYSe5NNMpsddQwAmmxQJ1AAAApMlsqcB2B3HPAQAAZNphqZ49e8YU6KrupX///hfMlpo/f37athIAACA9wo1qYeKudwMAAJBpw82MGTPSryUAAAChWqEYAAAgXBFuAACAVwg3AADAK4QbAADgFcINAADwCuEGAAB4JVXbLwBAuJoQuTXUTQAQIvTcAAAArxBuAACAVwg3AADAK4QbAADgFcINAADwCuEGAAB4hXADAAC8QrgBAABeIdwAAACvEG4AAIBXCDcAAMArhBsAAOAVwg0AAPAK4QYAAHiFcAMAALxCuAEAAF4h3AAAAK8QbgAAgFcINwAAwCuEGwAA4BXCDQAA8ArhBgAAeIVwAwAAvEK4AQAAXiHcAAAArxBuAACAVwg3AADAK4QbAADgFcINAADwCuEGAJJoQuRWdwAIb4QbAADglZCGmxUrVliHDh2sVKlSli1bNlu4cOFFn7Ns2TJr0KCB5cmTxypXrmwzZ87MkLYCAIDMIaTh5sSJE1avXj2bPHlykh7//fffW/v27a1Vq1b21Vdf2ZAhQ6xv3762ZMmSdG8rgMyDoSMga8sZyje/6aab3JFUU6dOtYoVK9q4cePc7Ro1athnn31mEyZMsLZt26ZjSwEAQGaRqWpuVq1aZa1bt451TqFG5xNy6tQpO3r0aKwDAAD4K1OFm3379lmJEiVindNtBZbff/893ueMHj3aChcuHHOULVs2g1oLAABCIVOFm5QYMWKEHTlyJObYvXt3qJsEAAB8rblJroiICNu/f3+sc7pdqFAhy5cvX7zP0awqHQAAIGvIVD03zZo1s6VLl8Y6FxkZ6c4DAACEPNwcP37cTenWEZjqrd9HRUXFDCl179495vH9+/e3nTt32oMPPmjfffedvfjii/bGG2/Y0KFDQ/YZAABAeAlpuFm7dq1deeWV7pBhw4a5348cOdLd3rt3b0zQEU0Df++991xvjdbH0ZTwl19+mWngAAAgRrbo6Ohoy0I0s0qzplRcrFodAP5J70X8hrapmq6vDyB11+9MVXMDAABwMYQbAADgFcINAADwCuEGAAB4hXADAAC8QrgBAABeIdwAAACvEG4AAIBXCDcAAMArhBsAAOAVwg0AAPAK4QYAAHiFcAMAALxCuAEAAF4h3AAAAK8QbgAAgFcINwAAwCuEGwAA4BXCDQAA8ArhBgCSaULk1lA3AUAiCDcAAMArhBsAAOAVwg0AAPAK4QYAAHglZ6gbAAAZrWnUSxecW13unpC0BUDaI9wA8AazmAAIw1IAAMArhBsAAOAVwg0AAPAK4QYAAHiFcAMAALxCuAEAAF4h3AAAAK8QbgAAgFcINwAAwCuEGwAA4BXCDQAA8ArhBgAAeIVwAwAAvEK4AQAAXiHcAAAAr4RFuJk8ebJVqFDB8ubNa1dddZWtWbMmwcfOnDnTsmXLFuvQ8wAAAMIi3MybN8+GDRtmjz32mK1fv97q1atnbdu2tQMHDiT4nEKFCtnevXtjjl27dmVomwEAQPgKebgZP3689evXz3r16mU1a9a0qVOnWv78+W369OkJPke9NRERETFHiRIlMrTNAAAgfIU03Jw+fdrWrVtnrVu3/m+Dsmd3t1etWpXg844fP27ly5e3smXLWseOHW3z5s0JPvbUqVN29OjRWAcApNaEyK3uABB+Qhpufv75Zzt37twFPS+6vW/fvnifU61aNder884779icOXPs/Pnz1rx5c9uzZ0+8jx89erQVLlw45lAgAgAA/gr5sFRyNWvWzLp3727169e36667zubPn2+XX365TZs2Ld7Hjxgxwo4cORJz7N69O8PbDAAAMk5OC6FixYpZjhw5bP/+/bHO67ZqaZIiV65cduWVV9r27dvjvT9PnjzuAAAAWUNIe25y585tDRs2tKVLl8ac0zCTbquHJik0rPXNN99YyZIl07GlAAAgswhpz41oGniPHj2sUaNG1qRJE5s4caKdOHHCzZ4SDUGVLl3a1c7IE088YU2bNrXKlSvb4cOHbezYsW4qeN++fUP8SQAAQDgIebjp0qWLHTx40EaOHOmKiFVLs3jx4pgi46ioKDeDKuDQoUNu6rgee9lll7men5UrV7pp5AAAANmio6OjLQvRVHDNmlJxsRYDBOCPpE7Nbhr10gXnVpe7J0XvObRN1RQ9D0D6Xb9D3nMDAKnFejMAMvVUcAAAgMQQbgAAgFcINwAAwCuEGwAA4BXCDQAA8ArhBgAAeIVwAwAAvEK4AQAAXiHcAAAArxBuAGRqrE4MIC7CDQCkAuEKCD+EGwAA4BXCDQAA8ArhBgAAeIVwAwAAvEK4AQAAXiHcAAAArxBuAACAVwg3AADAK4QbAADgFcINAADwCuEGAAB4hXADAAC8QrgBgDTYPJMNNIHwQbgBAABeyRnqBgBAStBTAiAh9NwAAACvEG4AAIBXCDcAAMArhBsAAOAVwg0AAPAK4QYA0gjr3QDhgXADINMhQABIDOEGAAB4hXADAAC8QrgBAABeYfsFAJkGtTYAkoKeGwBIY4QwILQINwAAwCuEGwAA4JWwCDeTJ0+2ChUqWN68ee2qq66yNWvWJPr4N99806pXr+4eX6dOHXv//fczrK0AMl5mXBwvM7YZ8EXIw828efNs2LBh9thjj9n69eutXr161rZtWztw4EC8j1+5cqV17drV+vTpYxs2bLBOnTq5Y9OmTRnedgAAEH6yRUdHR4eyAeqpady4sU2aNMndPn/+vJUtW9YGDRpkDz300AWP79Kli504ccIWLVoUc65p06ZWv359mzp16kXf7+jRo1a4cGE7cuSIFSpUKI0/DYC0lh69H02jXrroY1aXuyfN3m9om6pp9lpAVnU0GdfvkE4FP336tK1bt85GjBgRcy579uzWunVrW7VqVbzP0Xn19ARTT8/ChQvTvb0AMoZvwzmBz0PIATJGSMPNzz//bOfOnbMSJUrEOq/b3333XbzP2bdvX7yP1/n4nDp1yh0BSnyBBAggdCZ/vP2ij2m8Z0a6vPeJJDymzpZ/pPn7frTlj1+/LNMr5tyA6yun+fsAPgpct5My4OT9In6jR4+2UaNGXXBeQ18AEBp/DMPLwyFtB5D5HDt2zA1PhW24KVasmOXIkcP2798f67xuR0RExPscnU/O4zXkFTyMpZqeX3/91YoWLWrZsmWzzJ5iFdJ2795N/VCY4mcU/vgZhTd+PuHvaAb9jNRjo2BTqlSpiz42pOEmd+7c1rBhQ1u6dKmb8RQIH7o9cODAeJ/TrFkzd/+QIUNizkVGRrrz8cmTJ487gl166aXmE/1h4i99eONnFP74GYU3fj7hr1AG/Iwu1mMTNsNS6lXp0aOHNWrUyJo0aWITJ050s6F69fpjTLp79+5WunRpN7wkgwcPtuuuu87GjRtn7du3t9dff93Wrl1rL7108dkPAADAfyEPN5raffDgQRs5cqQrCtaU7sWLF8cUDUdFRbkZVAHNmze3uXPn2qOPPmoPP/ywValSxc2Uql27dgg/BQAACBchDzeiIaiEhqGWLVt2wbnbbrvNHVmdhtu0+GHcYTeED35G4Y+fUXjj5xP+8oThzyjki/gBAAB4tf0CAABAWiLcAAAArxBuAACAVwg3ntFWE5pxpgUKv/rqq1A3B//xww8/uJ3sK1asaPny5bNKlSq5Ajztr4bQmTx5slWoUMHy5s3rNvFds2ZNqJuE/9DyH9pUuWDBgla8eHG3FtqWLf/ZvwJh6dlnn3XXnuB16EKFcOOZBx98MEmrNyJjaa80LVA5bdo027x5s02YMMHtYq/lDBAa8+bNc+tsKWSuX7/e6tWr5zbhPXDgQKibBjNbvny5DRgwwFavXu0Waj1z5ozdeOONbh00hJ8vv/zS/ftWt25dCwfMlvLIBx984P6xfvvtt61WrVq2YcMG14uD8DR27FibMmWK7dy5M9RNyZLUU6OegUmT/tjnSeFTS8gPGjTIHnrooVA3D3FoPTT14Cj0XHvttaFuDoIcP37cGjRoYC+++KI99dRT7rqjBXlDiZ4bT2h/rX79+tk///lPy58/f6ibgyTQDvVFihQJdTOyJA0Hrlu3zlq3bh1zTouF6vaqVatC2jYk/PdF+DsTfgYMGOB2DAj++xRqYbGIH1JHnW89e/a0/v37u20sVN+B8LZ9+3b7xz/+Yc8991yom5Il/fzzz3bu3LmYldADdFtDiAgv6lVTHUeLFi1YjT7MvP76625YV8NS4YSemzCmrnEVZyV26B9iXSS1U6p2QEd4/oyC/fjjj9auXTu3yrZ62wBcvGdg06ZN7kKK8LF792633+Orr77qivLDCTU3YT7G/MsvvyT6mCuuuMJuv/12e/fdd92FNED/K82RI4fdddddNmvWrAxobdaU1J9R7ty53e9/+ukna9mypTVt2tRmzpwZa980ZOywlIZv33rrLTcLJ0Cb+B4+fNjeeeedkLYP/6WtefTzWLFihZttiPCxcOFCu/XWW921Jvjao2uR/m3T7N3g+zIS4cYD2lz06NGjMbd1AdWsD/3DraLJMmXKhLR9+G+PTatWraxhw4Y2Z86ckP2lxx/0d6NJkyau5zMw9FGuXDl3MaWgOPR0aVJx94IFC9weg9okGeHl2LFjtmvXrljnevXqZdWrV7e//e1vIR1CpObGA/oHOdgll1ziftVaKgSb8Ak26rEpX768q7NRj09ARERESNuWVWlmoXpqVKemkKPZHZpmrH+cER5DUXPnznW9NlrrZt++fe584cKF3VpRCL2CBQteEGAKFChgRYsWDXltFOEGyABap0NFxDriBk46T0OjS5cuLmSOHDnSXTg1fXXx4sUXFBkjNLRMgug/BcFmzJjhJlAAiWFYCgAAeIVqRgAA4BXCDQAA8ArhBgAAeIVwAwAAvEK4AQAAXiHcAAAArxBuAACAVwg3AADAK4QbAF7QSrZDhgwJdTMAhAHCDYCQ69Chg7Vr1y7e+z799FO3y/DGjRszvF0AMifCDYCQ69Onj9t/a8+ePRfcp72EtLll3bp1Q9I2AJkP4QZAyN1yyy12+eWX28yZM2OdP378uL355pvWqVMn69q1q5UuXdry589vderUsddeey3R11Rvz8KFC2Odu/TSS2O9x+7du+32229354sUKWIdO3a0H374IY0/HYCMRrgBEHI5c+a07t27u+ARvJevgs25c+esW7du1rBhQ3vvvfds06ZNds8999jdd99ta9asSfF7njlzxtq2bWsFCxZ0Q1+ff/65XXLJJW547PTp02n0yQCEAuEGQFjo3bu37dixw5YvXx5rSOpPf/qTlS9f3oYPH27169e3K664wgYNGuRCyBtvvJHi95s3b56dP3/eXn75ZdcTVKNGDfd+UVFRtmzZsjT6VABCgXADICxUr17dmjdvbtOnT3e3t2/f7npUVI+j3psnn3zShRANH6mHZcmSJS6IpNTXX3/t3kM9N3o9HXrtkydPupAFIPPKGeoGAECAgox6ZSZPnux6USpVqmTXXXedjRkzxp5//nmbOHGiCzgFChRw074TGz5SzU3wEFdgKCq4nkdDXa+++uoFz1X9D4DMi3ADIGyouHfw4ME2d+5cmz17tt13330upKgeRsW+qr0RDSdt3brVatasmeBrKaDs3bs35va2bdvst99+i7ndoEEDNzRVvHhxK1SoUDp/MgAZiWEpAGFDQ0NdunSxESNGuGDSs2dPd75KlSpuqvjKlSvt22+/tXvvvdf279+f6Gtdf/31NmnSJNuwYYOtXbvW+vfvb7ly5Yq5/6677rJixYq50KThr++//97V2tx///3xTkkHkHkQbgCE3dDUoUOH3EymUqVKuXOPPvqo62nROa1EHBER4aaHJ2bcuHFWtmxZu+aaa+zOO+90BcmaRh6g369YscLKlStnnTt3dgXFem/V3NCTA2Ru2aLjDkoDAABkYvTcAAAArxBuAACAVwg3AADAK4QbAADgFcINAADwCuEGAAB4hXADAAC8QrgBAABeIdwAAACvEG4AAIBXCDcAAMArhBsAAGA++X8tPFk0GhVDoQAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# convert to ndarray\n",
    "token_values = token_embeddings.detach().numpy().flatten()\n",
    "position_values = position_embeddings.detach().numpy().flatten()\n",
    "\n",
    "# histogram\n",
    "plt.hist(token_values, bins=100, alpha=0.5, label='Token Embeddings')\n",
    "plt.hist(position_values, bins=100, alpha=0.5, label='Position Embeddings')\n",
    "plt.legend()\n",
    "plt.xlabel('Value')\n",
    "plt.ylabel('Frequency')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logits\t tensor([[ -94.9980,  -98.1901,  -99.6383,  -99.6800,  -99.9885, -100.4567,\n",
      "         -100.5085, -101.0051, -101.0531, -101.0559]])\n",
      "ids\t tensor([[16039,   656,   736,   284,   287, 10574,   866, 14917,   319,   625]])\n",
      "\n",
      "Output probability distributions for varying temperature (top-k=10)\n",
      "tok_id\t token\t       T=1.0   T=0.5   T=1.5\n",
      "16039\t' asleep'      92.4%   99.8%   74.1%\n",
      "656\t' into'         3.8%    0.2%    8.8%\n",
      "736\t' back'         0.9%    0.0%    3.4%\n",
      "284\t' to'           0.9%    0.0%    3.3%\n",
      "287\t' in'           0.6%    0.0%    2.7%\n",
      "10574\t' silent'       0.4%    0.0%    1.9%\n",
      "866\t' down'         0.4%    0.0%    1.9%\n",
      "14917\t' unconscious'  0.2%    0.0%    1.4%\n",
      "319\t' on'           0.2%    0.0%    1.3%\n",
      "625\t' over'         0.2%    0.0%    1.3%\n"
     ]
    }
   ],
   "source": [
    "# for comparison: how high are logits for very obvious predictions?\n",
    "\n",
    "input_string = \"I crawled into bed, closed my eyes, and went to\" # sleep: -75, 75%\n",
    "input_string = \"I crawled into bed, closed my eyes, and fell\" # asleep: -95, 92%\n",
    "token_ids = tokenizer(input_string, return_tensors=\"pt\").input_ids\n",
    "\n",
    "with torch.no_grad():\n",
    "    outputs = model_tied_unembed(token_ids, use_cache=False)\n",
    "logits = outputs.logits\n",
    "final_token_logits = logits[:, -1, :]\n",
    "\n",
    "top_10_logits, top_10_token_indices = torch.topk(final_token_logits, 10, dim=-1)\n",
    "print('logits\\t', top_10_logits)\n",
    "print('ids\\t', top_10_token_indices)\n",
    "\n",
    "softmax = torch.nn.Softmax(dim=-1)\n",
    "\n",
    "probs = softmax(top_10_logits)\n",
    "\n",
    "cold_temp = 0.5\n",
    "top_10_logits_cold = top_10_logits / cold_temp\n",
    "probs_cold = softmax(top_10_logits_cold)\n",
    "\n",
    "hot_temp = 1.5\n",
    "top_10_logits_hot = top_10_logits / hot_temp\n",
    "probs_hot = softmax(top_10_logits_hot)\n",
    "\n",
    "print('\\nOutput probability distributions for varying temperature (top-k=10)')\n",
    "print(f'tok_id\\t token\\t       T=1.0   T=0.5   T=1.5')\n",
    "for i in range(10):\n",
    "    tok_id = top_10_token_indices[0][i]\n",
    "    token = repr(tokenizer.decode(tok_id))  # using repr() to escape e.g. new lines\n",
    "    prob = probs[0][i]*100\n",
    "    prob_cold = probs_cold[0][i]*100\n",
    "    prob_hot = probs_hot[0][i]*100\n",
    "    print(f'{tok_id.item()}\\t{token:14s}{prob:5.1f}%  {prob_cold:5.1f}%  {prob_hot:5.1f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================== Unscaled softmax ====================\n",
      "my softmax: ['0.0152', '0.0413', '0.1124', '0.8303', '0.0008']\n",
      "torch smax: ['0.0152', '0.0413', '0.1124', '0.8303', '0.0008']\n",
      "==================== Temperature 1 ====================\n",
      "prescaling: ['0.0152', '0.0413', '0.1124', '0.8303', '0.0008']\n",
      "sftmaxtemp: ['0.0152', '0.0413', '0.1124', '0.8303', '0.0008']\n",
      "torch smax: ['0.0152', '0.0413', '0.1124', '0.8303', '0.0008']\n",
      "==================== Temperature 0.3 ====================\n",
      "prescaling: ['0.0000', '0.0000', '0.0013', '0.9987', '0.0000']\n",
      "sftmaxtemp: ['0.0000', '0.0000', '0.0013', '0.9987', '0.0000']\n",
      "torch smax: ['0.0000', '0.0000', '0.0013', '0.9987', '0.0000']\n",
      "==================== Temperature 1.85 ====================\n",
      "prescaling: ['0.0687', '0.1180', '0.2026', '0.5972', '0.0136']\n",
      "sftmaxtemp: ['0.0687', '0.1180', '0.2026', '0.5972', '0.0136']\n",
      "torch smax: ['0.0687', '0.1180', '0.2026', '0.5972', '0.0136']\n",
      "==================== Temperature 10 ====================\n",
      "prescaling: ['0.1799', '0.1988', '0.2197', '0.2684', '0.1333']\n",
      "sftmaxtemp: ['0.1799', '0.1988', '0.2197', '0.2684', '0.1333']\n",
      "torch smax: ['0.1799', '0.1988', '0.2197', '0.2684', '0.1333']\n"
     ]
    }
   ],
   "source": [
    "# convince myself temperature scaling before softmax is the same as within softmax\n",
    "PRECISION = 4\n",
    "V = [1., 2., 3., 5., -2.]\n",
    "T = torch.tensor(V)\n",
    "\n",
    "def softmax(vec, temp=1):\n",
    "    denominator = sum(math.exp(x / temp) for x in vec)\n",
    "    return [math.exp(e / temp) / denominator for e in vec]\n",
    "\n",
    "print('=' * 20, 'Unscaled softmax', '=' * 20)\n",
    "print('my softmax: ', end='')\n",
    "print([f\"{v:.{PRECISION}f}\" for v in softmax(V)])\n",
    "print('torch smax: ', end='')\n",
    "print([f'{v.item():.{PRECISION}f}' for v in torch.softmax(T, dim=0)])\n",
    "\n",
    "for temp in 1, 0.3, 1.85, 10:\n",
    "    print('=' * 20, 'Temperature', temp, '=' * 20)\n",
    "    print('prescaling: ', end='')\n",
    "    print([f'{psv:.{PRECISION}f}' for psv in softmax([v / temp for v in V])])\n",
    "    print('sftmaxtemp: ', end='')\n",
    "    print([f'{smt:.{PRECISION}f}' for smt in softmax(V, temp)])\n",
    "    print('torch smax: ', end='')\n",
    "    print([f'{tsmt:.{PRECISION}f}' for tsmt in torch.softmax(T / temp, dim=0)])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
